# ğŸ§  Breast Cancer Classification using Logistic Regression & Multicollinearity Analysis

### ğŸ“Œ Overview  
This project is an introductory machine learning analysis focused on predicting breast cancer diagnosis using clinical features. It demonstrates a complete ML workflow â€” from exploratory analysis to model evaluation â€” while diving deeper into an important statistical concept: **multicollinearity**.

This project helped build foundational skills that I apply in more advanced, domain-specific analytics projects (e.g., fraud detection in fintech).

---

### ğŸ¯ Objectives  
- Explore the Breast Cancer dataset  
- Understand relationships between features  
- Detect and evaluate **multicollinearity**  
- Apply **Logistic Regression** for binary classification  
- Evaluate model performance using standard metrics  

---

### ğŸ“‚ Dataset  
Dataset: Breast Cancer Wisconsin Diagnostic Dataset  
Source: Scikit-learn / UCI Machine Learning Repository  
Target variable:  
- `diagnosis` â€” **M = Malignant** / **B = Benign**

---

### ğŸ” Steps Performed  
âœ” Data loading and cleaning  
âœ” Feature correlation and visualization  
âœ” Multicollinearity check using **Variance Inflation Factor (VIF)**  
âœ” Feature selection and reduction  
âœ” Logistic Regression Model training  
âœ” Performance evaluation and interpretation  

---

### ğŸ“Š Model Evaluation  
Metrics used:

- Accuracy  
- Precision  
- Recall  
- Confusion Matrix  
- ROCâ€“AUC Curve  

These measures help assess not just correctness but also the modelâ€™s **ability to detect malignant cases**, which is clinically important.

---

### ğŸ§© Key Learning & Insights  
- Highly correlated features can **distort model interpretability**
- Removing multicollinear features improves model stability  
- Logistic regression can be a strong baseline for diagnostic prediction  
- Domain context matters: minimizing false negatives is crucial in healthcare  

---

### ğŸ“¦ Tech Stack  
| Tool | Purpose |
|------|---------|
| Python | Programming |
| Pandas, NumPy | Data manipulation |
| Matplotlib, Seaborn | Visualization |
| Scikit-learn | Modeling & metrics |
| Statsmodels | VIF / regression diagnostics |
| Jupyter Notebook | Analysis environment |

---

### ğŸš€ Future Improvements  
- Try **regularization** (Lasso/Ridge) to handle multicollinearity automatically  
- Compare with tree-based models (Random Forest, XGBoost)  
- Feature scaling + advanced preprocessing  
- Expand explainability using SHAP or feature importance  

---

### ğŸ“Œ Status  
Learning project âœ”  
Complete and published âœ”  
Actively improving ML fundamentals âœ”  

---

### âœï¸ Author  
**Avanti Bhattacharya**  
Data Science & Economics, Krea University  
Focused on delivering actionable insights through data analytics.

---

## â­ If this project helped or inspired you, feel free to star the repo!
